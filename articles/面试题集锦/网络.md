
### 浏览器持久化存储
* sessionStorage、localStorage，cookie
* Service Worker
###  http相关
* 状态码
* 常见请求头，响应头
* 跨域
* http的强缓存和协商缓存
* http2.0的多路复用的原理，多路复用有哪些优势？
* https的原理以及区别，怎么构建https的链接
* CDN是什么，为什么要使用CDN

- 从输入URL到页面加载完成，发生了什么？
  * 首先我们需要通过DNS（域名解析系统）将URL解析为对应的IP地址
  * 然后与这个IP地址确定的那台服务器建立起TCP网络连接 （TCP的三次握手，长连接）
  * 随后我们向服务端抛出我们的HTTP请求 （HTTP知识点：状态码，请求头，浏览器缓存、异步请求）
  * 服务端处理好我们的请求后，将目标数据放到HTTP响应里返回给客户端 （响应头、浏览器缓存）
  * 拿到响应数据的浏览器就可以走一个渲染的流程，渲染完毕，页面便呈现给用户，并时刻等待响应用户的操作 （浏览器渲染机制、重绘与重排）

- 由上题引发出来的每一个步骤的优化措施？
  * 减少DNS解析次数或者把解析前置 （浏览器DNS缓存、DNS prefetch）
  * TCP每次建立连接都要三次握手，很耗时间 （长连接、预连接、接入SPDY协议）
  * 减少HTTP请求次数和减少请求体积
    - webpack性能调优与Gzip压缩原理
    - 图片优化（压缩）
    - 利用浏览器缓存机制
  * 渲染
    - 服务端渲染的探索
    - JS/CSS 性能方案
    - DOM优化： 事件循环与异步更新、回流与重绘的考量
    - 懒加载
  后两点（网络层面、渲染层面）是前端工程师需要详细掌握的两点

- webpack性能调优与Gzip压缩原理
  * 减少webpack构建时间
    - 不要让loader做太多的事情，以babel-loader为例，babel-loader是强大的，无疑它也是最慢的。我们可以使用include、exclude来排除一些文件不使用loader
    - 开启缓存将转译结果缓存至文件系统 `loader: 'babel-loader?cacheDirectory=true'`
    - node_modules下面的第三方库庞大的可怕，处理第三方库的打包推荐使用DllPlugin，DllPlugin是基于Windows动态链接库（dll）的思想被创作出来的。这个插件会把第三方库单独打包到一个文件中，这个文件就是一个单纯的依赖库。这个依赖库不会跟着你的业务代码一起被重新打包，只有当依赖自身发生版本变化时才会重新打包。
    - Happypack-将loader由单进程转化为多进程打包，webpack是单线程的，就算此刻存在多个任务，你也只能排队一个接一个地等待处理。这是webpack的缺点，好在我们的CPU是多核的，Happypack会充分释放CPU在多核并发方面的优势，帮我们把任务分解给多个子进程去并发执行，大大提升打包效率。
  * 减小webpack打包体积
    - 文件结构可视化，找出导致体积过大的原因，`webpack-bundle-analyzer`
    - 删除冗余代码， 一个比较典型的应用：`Tree-Shaking`：基于import/export语法，Tree-Shaking可以在编译的过程中获悉哪些模块并没有真正的被使用，这些没用的代码在最后打包的时候会被去除。Tree-Shaking的针对性很强，它更适合用来处理模块级别的冗余代码。对于粒度更细的冗余代码的去除，往往会被整合进JS或CSS的压缩和分离过程中，比如webpack4的`uglifyjs-webpack-plugin`
    - 按需加载。import()

- 浏览器缓存机制与缓存策略
  浏览器缓存的四个方面：
  * Memory Cache
  * Service Worker Cache
  * HTTP Cache
    - *强缓存*： 优先级比较高的是强缓存，在命中强缓存失败的情况下，才会走协商缓存，强缓存是利用http头中的Expires和Cache-Control两个字段来控制的。强缓存中，当请求再次发出时，浏览器会根据其中的expires和cache-control判断目标资源是否“命中”强缓存，若命中则直接从缓存中获取资源，不会与服务器发生通信。强缓存命中的情况下，http返回码为200。
    - 强缓存的实现：  
      * expires:当服务器返回响应时，在Response Headers中将过期时间写入expires字段。expires是一个时间戳，接下来我们试图再次向服务器发起请求资源，浏览器就会先对比本地时间和expires的时间戳，如果本地时间小于expires设定的过期时间，那么就会直接去缓存中取这个资源。由于时间戳是服务器来定义的，而本地时间的取值却来自于客户端，因此，expires的工作机制对客户端时间与服务端时间的一致性提出了极高的要求，若服务器与客户端存在时差，将带来意料之外的结果。
      * cache-control: max-age=31536000。max-age（秒）是一个时间长度。在max-age机制下，资源的缓存时间不在受服务器时间的限制，客户端会记录请求到资源的时间点，以此作为时间起点，从而确保参与计算的两个时间结点都来源与客户端，以便实现更加精准的判断。如果项目中有代理服务器的话，考虑s-maxage字段
      * 以上cache-control（HTTP1.1）是对expires的补位/替换，在当下普遍使用cache-control,但是如果做向下兼容，那两者都须使用，cache-control的优先级高于expires
      * cache-control: no-cache/no-store 设置了no-cache浏览器会直接略过强缓存直接走协商缓存。no-store是什么缓存都不用，只能向服务器请求资源，返回最新数据
      
    - *协商缓存*：浏览器和服务器合作下的缓存策略，协商缓存机制下，浏览器需要向服务器去询问相关的缓存信息，进而判断是重新发起请求下载完整的响应还是从本地获取缓存资源。如果服务端提示缓存资源未改动（Not Modified），资源就会被重定向到浏览器缓存，这种情况下网络请求对应的状态码是304
    - 什么时候下走协商缓存？
      * 命中强缓存失败
      * expires和cache-control过期
      * cache-control: no-cache
    - 协商缓存的实现，从Last-Modified到Etag
      * Last-Modified是一个时间戳，如果我们启用了协商缓存，它会在首次请求随着Response Headers返回： `Last-Modified: Fri, 27 Oct 2017 06:35:57 GMT`,随后我们每次请求都会带上一个叫If-Modified-Since的时间戳字段，它的值正是上一次返回给浏览器的last-modified的值 `If-Modified-Since: Fri, 27 Oct 2017 06:35:57 GMT`,服务器收到这个时间戳后，会对比时间戳和资源在服务器上的最后修改时间是否一致，从而判断资源是否发生了变化。如果发生了变化，就返回一个完整的响应内容，并在Response Headers中添加新的Last-Modified值，否则返回如上图中的304响应，Response Headers不会在添加Last-Modified字段。
      * 协商缓存有两个存在的问题：
        - 我们编辑了文件，但是又把文件内容改回来了。服务器只知道你编辑了文件，依然会生成一个Last-Modified字段，虽然文件内容并没有改变，但是还是发起了一次资源的请求。
        - 当我们修改文件的速度过快时（比如花了100ms完成了改动），由于If-Modified-Since只能检查到以秒为最小计量单位的时间差，所以它是感知不到这个改动的-该重新请求的时候，反而没有重新请求了。
        
      * 问题：服务器是怎么感知文件的变化，从而重新得出Last-Modified的时间戳的？
      * Etag为了解决Last-Modified的两个问题，作为补充出现了
        - Etag是服务器为每个资源生成的唯一的标识字符串，这个标识字符串是基于文件内容编码的，只要文件内容不同它们对应的Etag就会不同，反之亦然。因此Etag能精准的感知文件的变化。
        - Etag和Last-Modified类似，当首次请求的时候，我们会在响应头里获取到一个最初的标识字符串，`Etag: W/"2a3b-1602480f459`,那么下一次请求的时候，请求头里就会带上一个值相同的，名为if-None-Match的字符串共服务端对比了 `If-None-Match: W/"2a3b-1602480f459"`。
        - Etag的生成需要服务器额外的开销，会影响服务器的性能，这是它的弊端。因此启用Etag需要我们审时度势。Etag并不能代替Last-Modified，它只能作为Last-Modified的补充和强化存在。Etag在感知文件变化上比Last-Modified更加准确，优先级也更高。当Etag和Last-Modified同时存在时，以Etag为准。
  * Push Cache